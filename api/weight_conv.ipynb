{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight_conv_vanilla.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile weight_conv_vanilla.py\n",
    "import safetensors\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sparseopt.attns.act_sparse_nbits import MFSparseNbits, QuantTool\n",
    "from sparseopt.compress.compress_model import CompressOPT\n",
    "from sparseopt.compress.compress_linear import CompressedLinear\n",
    "from sparseopt.compress.compress_config import CompressConfig, LinearConfig, SparseQuantizeConfig\n",
    "\n",
    "from einops import rearrange\n",
    "from transformers.models.deepseek_v3.modeling_deepseek_v3 import DeepseekV3ForCausalLM, DeepseekV3DecoderLayer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DynamicCache\n",
    "from transformers.integrations.finegrained_fp8 import FP8Linear\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import typing\n",
    "from typing import Optional, Union, List, Tuple, Dict, Mapping, Any, Callable\n",
    "import copy\n",
    "import shutil\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to weight_conv_vanilla.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile weight_conv_vanilla.py -a\n",
    "in_weight_dir = \"/ssd01/models/DeepSeek-V3.1-Terminus\"\n",
    "out_weight_dir = \"/ssd01/models/DeepSeek-V3.1-Terminus-MF-Int8\"\n",
    "in_weight_dir = \"/ssd01/models/DeepSeek-V3.2-Exp\"\n",
    "out_weight_dir = \"/ssd01/models/DeepSeek-V3.2-Exp-MF-Int8\"\n",
    "index_file = os.path.join(in_weight_dir, \"model.safetensors.index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to weight_conv_vanilla.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile weight_conv_vanilla.py -a\n",
    "with open(index_file) as f:\n",
    "    weight_map = json.load(f)[\"weight_map\"]\n",
    "weight_map_ref = defaultdict(list)\n",
    "for w, fpath in weight_map.items():\n",
    "    weight_map_ref[fpath].append(w)\n",
    "for fpath, w_list in weight_map_ref.items():\n",
    "    print(f\"{fpath}: {len(w_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to weight_conv_vanilla.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile weight_conv_vanilla.py -a\n",
    "# vanilla version\n",
    "tool = QuantTool(\n",
    "    bank_size=64,\n",
    "    mode=\"per_bank\",\n",
    "    dtype=\"int8\",\n",
    "    symmetric=True\n",
    ")\n",
    "w_block = [128, 128]\n",
    "\n",
    "weights = defaultdict(dict)\n",
    "def get_tensor(name):\n",
    "    return weights[weight_map[name]][name]\n",
    "\n",
    "def set_tensor(name, tensor):\n",
    "    weights[weight_map[name]][name] = tensor\n",
    "\n",
    "for fpath, w_list in tqdm(weight_map_ref.items(), desc=\"Loading weights\"):\n",
    "    in_file = os.path.join(in_weight_dir, fpath)\n",
    "    with safetensors.safe_open(in_file, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for w_name in w_list:\n",
    "            weights[fpath][w_name] = f.get_tensor(w_name)\n",
    "\n",
    "for name in tqdm(list(weight_map.keys())[:], desc=\"Processing weights\"):\n",
    "    if name.endswith(\".weight_scale_inv\"):\n",
    "        s_name = name\n",
    "        w_name = name.replace(\".weight_scale_inv\", \".weight\")\n",
    "        \n",
    "        scale = get_tensor(s_name)\n",
    "        weight = get_tensor(w_name)\n",
    "        w_shape = weight.shape\n",
    "        \n",
    "        scale = scale.repeat_interleave(w_block[0], dim=0)\n",
    "        scale = scale.repeat_interleave(w_block[1], dim=1)\n",
    "        weight = weight.to(scale.dtype) * \\\n",
    "            scale[:weight.size(0), :weight.size(1)]\n",
    "\n",
    "        weight_ori = weight\n",
    "\n",
    "        # quantize: int8 weight + bfloat16 scale\n",
    "        weight = tool.transform.preprocess(weight)\n",
    "        weight, scale = tool.sym_quant(weight)\n",
    "        weight = tool.transform.postprocess(weight).to(torch.int8)\n",
    "        scale = tool.transform.postprocess(scale).to(torch.bfloat16)\n",
    "        # tqdm.write(w_name, weight.dtype, weight.shape, scale.dtype, scale.shape)\n",
    "\n",
    "        weight_new = weight.to(torch.bfloat16) * scale.repeat_interleave(64, dim=-1)\n",
    "        weight_ori = weight_ori.view(-1)\n",
    "        weight_new = weight_new.view(-1)\n",
    "        # diff = ((weight_new - weight_ori).abs() / weight_ori.abs())\n",
    "        diff = (weight_new - weight_ori).abs()\n",
    "        diff[weight_ori == 0] = 0\n",
    "        value, index = diff.max(dim=0)\n",
    "        value_ori = weight_ori[index]\n",
    "        value_new = weight_new[index]\n",
    "        tqdm.write(f\"{w_name}: {value, value_ori, value_new}\")\n",
    "\n",
    "        # update weights\n",
    "        set_tensor(s_name, scale)\n",
    "        set_tensor(w_name, weight)\n",
    "\n",
    "for fpath, w_dict in tqdm(weights.items(), desc=\"Saving weights\"):\n",
    "    out_file = os.path.join(out_weight_dir, fpath)\n",
    "    safetensors.torch.save_file(weights[fpath], out_file)\n",
    "    tqdm.write(f\"Saved {len(w_dict)} weights to {out_file}\")\n",
    "file_list = [\n",
    "    \"configuration.json\",\n",
    "    \"configuration_deepseek.py\",\n",
    "    \"generation_config.json\",\n",
    "    \"tokenizer_config.json\",\n",
    "    \"tokenizer.json\",\n",
    "    \"modeling_deepseek.py\",\n",
    "    \"inference\",\n",
    "    \"config.json\",\n",
    "    \"model.safetensors.index.json\"\n",
    "]\n",
    "for filepath in file_list:\n",
    "    if os.path.exists(os.path.join(out_weight_dir, filepath)):\n",
    "        if os.path.isdir(os.path.join(in_weight_dir, filepath)):\n",
    "            shutil.copytree(\n",
    "                os.path.join(in_weight_dir, filepath),\n",
    "                os.path.join(out_weight_dir, filepath),\n",
    "                dirs_exist_ok=True\n",
    "            )\n",
    "        elif filepath == \"config.json\":\n",
    "            with open(os.path.join(out_weight_dir, filepath), mode=\"w\") as ofid, \\\n",
    "                    open(os.path.join(in_weight_dir, filepath), mode=\"r\") as ifid:\n",
    "                info = json.load(ifid)\n",
    "                info[\"quantization_config\"] = {\n",
    "                    \"activation_scheme\": \"dynamic\",\n",
    "                    \"mf_format\": True,\n",
    "                    \"quant_method\": \"blockwise_int8\",\n",
    "                    \"smooth\": False,\n",
    "                    \"w_sparsity\": 0,\n",
    "                    \"w_low_bits\": 0,\n",
    "                    \"mask_in_id\": False,\n",
    "                    \"weight_block_size\": [\n",
    "                        1,\n",
    "                        64\n",
    "                    ]\n",
    "                }\n",
    "                json.dump(info, ofid, indent=2, ensure_ascii=True)\n",
    "        else:\n",
    "            shutil.copy(\n",
    "                os.path.join(in_weight_dir, filepath),\n",
    "                os.path.join(out_weight_dir, filepath)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 163/163 [00:01<00:00, 105.34it/s]\n",
      "Processing weights:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  15%|█▌        | 3/20 [00:01<00:10,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ratio: 0.050000000000000044, error: 1056768.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 7168]) torch.bfloat16 tensor([[1.0469, 1.0547, 1.0625,  ..., 1.0469, 1.0547, 1.0469]],\n",
      "       dtype=torch.bfloat16)\n",
      "model.layers.0.self_attn.q_a_proj.weight: (tensor(0.0117), tensor(-0.2188), tensor(-0.2305, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  30%|███       | 6/20 [00:02<00:06,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ratio: 0.050000000000000044, error: 176128.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 1536]) torch.bfloat16 tensor([[1.0469, 1.0469, 1.0469,  ..., 1.0469, 1.0469, 1.0391]],\n",
      "       dtype=torch.bfloat16)\n",
      "model.layers.0.self_attn.q_b_proj.weight: (tensor(0.0703), tensor(1.1250), tensor(1.1953, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  40%|████      | 8/20 [00:03<00:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ratio: 0.050000000000000044, error: 630784.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 7168]) torch.bfloat16 tensor([[1.0547, 1.0547, 1.0625,  ..., 1.0547, 1.0547, 1.0469]],\n",
      "       dtype=torch.bfloat16)\n",
      "model.layers.0.self_attn.kv_a_proj_with_mqa.weight: (tensor(0.0430), tensor(0.8125), tensor(0.8555, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  55%|█████▌    | 11/20 [00:04<00:02,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ratio: 0.050000000000000044, error: 28544.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 512]) torch.bfloat16 tensor([[1.0469, 1.0469, 1.0469, 1.0469, 1.0469, 1.0391, 1.0469, 1.0469, 1.0469,\n",
      "         1.0547, 1.0625, 1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0469, 1.0469,\n",
      "         1.0469, 1.0547, 1.0469, 1.0547, 1.0547, 1.0469, 1.0469, 1.0625, 1.0547,\n",
      "         1.0547, 1.0469, 1.0547, 1.0547, 1.0547, 1.0469, 1.0547, 1.0547, 1.0469,\n",
      "         1.0469, 1.0469, 1.0469, 1.0469, 1.0469, 1.0547, 1.0547, 1.0391, 1.0391,\n",
      "         1.0547, 1.0469, 1.0547, 1.0469, 1.0547, 1.0469, 1.0391, 1.0469, 1.0391,\n",
      "         1.0469, 1.0391, 1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0547, 1.0469,\n",
      "         1.0469, 1.0547, 1.0547, 1.0547, 1.0391, 1.0547, 1.0625, 1.0547, 1.0547,\n",
      "         1.0469, 1.0391, 1.0469, 1.0469, 1.0469, 1.0547, 1.0547, 1.0469, 1.0469,\n",
      "         1.0547, 1.0469, 1.0469, 1.0547, 1.0547, 1.0469, 1.0469, 1.0469, 1.0547,\n",
      "         1.0547, 1.0469, 1.0469, 1.0469, 1.0625, 1.0469, 1.0547, 1.0547, 1.0547,\n",
      "         1.0547, 1.0469, 1.0469, 1.0469, 1.0547, 1.0469, 1.0469, 1.0469, 1.0469,\n",
      "         1.0625, 1.0625, 1.0391, 1.0469, 1.0625, 1.0625, 1.0391, 1.0547, 1.0547,\n",
      "         1.0391, 1.0625, 1.0547, 1.0547, 1.0625, 1.0547, 1.0547, 1.0469, 1.0547,\n",
      "         1.0625, 1.0547, 1.0625, 1.0391, 1.0391, 1.0469, 1.0547, 1.0547, 1.0547,\n",
      "         1.0391, 1.0547, 1.0547, 1.0469, 1.0547, 1.0547, 1.0469, 1.0391, 1.0547,\n",
      "         1.0469, 1.0547, 1.0625, 1.0469, 1.0547, 1.0625, 1.0312, 1.0547, 1.0469,\n",
      "         1.0469, 1.0547, 1.0547, 1.0547, 1.0312, 1.0547, 1.0625, 1.0391, 1.0547,\n",
      "         1.0469, 1.0469, 1.0547, 1.0469, 1.0625, 1.0625, 1.0547, 1.0469, 1.0625,\n",
      "         1.0547, 1.0547, 1.0547, 1.0547, 1.0547, 1.0391, 1.0469, 1.0547, 1.0547,\n",
      "         1.0547, 1.0547, 1.0547, 1.0469, 1.0469, 1.0469, 1.0625, 1.0547, 1.0469,\n",
      "         1.0625, 1.0625, 1.0391, 1.0469, 1.0469, 1.0547, 1.0469, 1.0547, 1.0547,\n",
      "         1.0547, 1.0547, 1.0469, 1.0469, 1.0547, 1.0547, 1.0547, 1.0469, 1.0547,\n",
      "         1.0547, 1.0391, 1.0547, 1.0547, 1.0469, 1.0547, 1.0469, 1.0391, 1.0469,\n",
      "         1.0469, 1.0469, 1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0391, 1.0547,\n",
      "         1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0469, 1.0547, 1.0469, 1.0312,\n",
      "         1.0547, 1.0625, 1.0547, 1.0547, 1.0391, 1.0469, 1.0547, 1.0547, 1.0625,\n",
      "         1.0547, 1.0469, 1.0391, 1.0391, 1.0547, 1.0469, 1.0547, 1.0391, 1.0469,\n",
      "         1.0547, 1.0547, 1.0469, 1.0547, 1.0547, 1.0547, 1.0469, 1.0469, 1.0469,\n",
      "         1.0547, 1.0547, 1.0469, 1.0547, 1.0547, 1.0547, 1.0469, 1.0469, 1.0547,\n",
      "         1.0547, 1.0547, 1.0391, 1.0469, 1.0469, 1.0547, 1.0625, 1.0469, 1.0469,\n",
      "         1.0547, 1.0469, 1.0547, 1.0469, 1.0625, 1.0469, 1.0469, 1.0547, 1.0547,\n",
      "         1.0391, 1.0469, 1.0547, 1.0469, 1.0547, 1.0547, 1.0469, 1.0469, 1.0547,\n",
      "         1.0391, 1.0547, 1.0469, 1.0469, 1.0469, 1.0469, 1.0625, 1.0391, 1.0547,\n",
      "         1.0547, 1.0547, 1.0547, 1.0547, 1.0547, 1.0547, 1.0391, 1.0469, 1.0391,\n",
      "         1.0547, 1.0391, 1.0469, 1.0547, 1.0625, 1.0547, 1.0469, 1.0469, 1.0547,\n",
      "         1.0469, 1.0547, 1.0625, 1.0547, 1.0469, 1.0547, 1.0469, 1.0469, 1.0547,\n",
      "         1.0547, 1.0547, 1.0469, 1.0391, 1.0469, 1.0469, 1.0625, 1.0469, 1.0469,\n",
      "         1.0469, 1.0469, 1.0469, 1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0547,\n",
      "         1.0547, 1.0547, 1.0547, 1.0469, 1.0547, 1.0469, 1.0469, 1.0469, 1.0391,\n",
      "         1.0547, 1.0547, 1.0391, 1.0547, 1.0547, 1.0547, 1.0469, 1.0547, 1.0469,\n",
      "         1.0469, 1.0547, 1.0547, 1.0625, 1.0625, 1.0547, 1.0469, 1.0547, 1.0469,\n",
      "         1.0547, 1.0547, 1.0469, 1.0391, 1.0469, 1.0547, 1.0547, 1.0547, 1.0625,\n",
      "         1.0547, 1.0547, 1.0469, 1.0625, 1.0547, 1.0469, 1.0547, 1.0547, 1.0547,\n",
      "         1.0547, 1.0547, 1.0469, 1.0547, 1.0625, 1.0469, 1.0625, 1.0547, 1.0547,\n",
      "         1.0469, 1.0547, 1.0391, 1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0547,\n",
      "         1.0547, 1.0469, 1.0625, 1.0469, 1.0547, 1.0547, 1.0547, 1.0547, 1.0547,\n",
      "         1.0547, 1.0469, 1.0469, 1.0547, 1.0625, 1.0469, 1.0625, 1.0469, 1.0625,\n",
      "         1.0547, 1.0469, 1.0547, 1.0625, 1.0547, 1.0547, 1.0469, 1.0469, 1.0547,\n",
      "         1.0547, 1.0547, 1.0547, 1.0547, 1.0391, 1.0469, 1.0625, 1.0625, 1.0547,\n",
      "         1.0469, 1.0469, 1.0547, 1.0391, 1.0547, 1.0469, 1.0469, 1.0547, 1.0469,\n",
      "         1.0547, 1.0625, 1.0469, 1.0469, 1.0469, 1.0625, 1.0625, 1.0547, 1.0469,\n",
      "         1.0625, 1.0547, 1.0469, 1.0547, 1.0469, 1.0469, 1.0625, 1.0469, 1.0469,\n",
      "         1.0469, 1.0469, 1.0625, 1.0625, 1.0547, 1.0547, 1.0469, 1.0547, 1.0469,\n",
      "         1.0547, 1.0547, 1.0625, 1.0547, 1.0547, 1.0469, 1.0391, 1.0547, 1.0391,\n",
      "         1.0547, 1.0547, 1.0469, 1.0391, 1.0625, 1.0547, 1.0547, 1.0469, 1.0547,\n",
      "         1.0391, 1.0469, 1.0469, 1.0469, 1.0547, 1.0547, 1.0547, 1.0391]],\n",
      "       dtype=torch.bfloat16)\n",
      "model.layers.0.self_attn.kv_b_proj.weight: (tensor(0.0156), tensor(0.3125), tensor(0.3281, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
      "Best ratio: 0.0, error: 2293760.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 16384]) torch.bfloat16 tensor([[1., 1., 1.,  ..., 1., 1., 1.]], dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  65%|██████▌   | 13/20 [00:17<00:15,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.o_proj.weight: (tensor(0.0026), tensor(0.4134), tensor(0.4160, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
      "Best ratio: 1.0, error: 2490368.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 7168]) torch.bfloat16 tensor([[2.6719, 3.0156, 2.4844,  ..., 2.9531, 2.8594, 2.6250]],\n",
      "       dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  75%|███████▌  | 15/20 [00:24<00:12,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.gate_proj.weight: (tensor(0.7266), tensor(0.3125), tensor(1.0391, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
      "Best ratio: 0.050000000000000044, error: 493568.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 7168]) torch.bfloat16 tensor([[1.0391, 1.0547, 1.0547,  ..., 1.0469, 1.0469, 1.0469]],\n",
      "       dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights:  85%|████████▌ | 17/20 [00:31<00:08,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.up_proj.weight: (tensor(0.0127), tensor(-0.2344), tensor(-0.2471, dtype=torch.bfloat16))\n",
      "Smoothing ...\n",
      "Searching best scale with ratio in [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
      "Best ratio: 0.0, error: 1769472.0\n",
      "Finish smoothing\n",
      "torch.Size([1, 18432]) torch.bfloat16 tensor([[1., 1., 1.,  ..., 1., 1., 1.]], dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weights: 100%|██████████| 20/20 [00:49<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.down_proj.weight: (tensor(0.0024), tensor(0.0508), tensor(0.0532, dtype=torch.bfloat16))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# smooth scale version\n",
    "tool = QuantTool(\n",
    "    bank_size=64,\n",
    "    mode=\"per_bank\",\n",
    "    dtype=\"int8\",\n",
    "    symmetric=True\n",
    ")\n",
    "w_block = [128, 128]\n",
    "\n",
    "weights = defaultdict(dict)\n",
    "def get_tensor(name):\n",
    "    return weights[weight_map[name]][name]\n",
    "\n",
    "def set_tensor(name, tensor):\n",
    "    weights[weight_map[name]][name] = tensor\n",
    "\n",
    "for fpath, w_list in tqdm(weight_map_ref.items(), desc=\"Loading weights\"):\n",
    "    in_file = os.path.join(in_weight_dir, fpath)\n",
    "    with safetensors.safe_open(in_file, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for w_name in w_list:\n",
    "            weights[fpath][w_name] = f.get_tensor(w_name)\n",
    "\n",
    "for name in tqdm(list(weight_map.keys())[:20], desc=\"Processing weights\"):\n",
    "    if name.endswith(\".weight_scale_inv\"):\n",
    "        s_name = name\n",
    "        w_name = name.replace(\".weight_scale_inv\", \".weight\")\n",
    "        \n",
    "        scale = get_tensor(s_name)\n",
    "        weight = get_tensor(w_name)\n",
    "        w_shape = weight.shape\n",
    "        \n",
    "        scale = scale.repeat_interleave(w_block[0], dim=0)\n",
    "        scale = scale.repeat_interleave(w_block[1], dim=1)\n",
    "        weight = weight.to(scale.dtype) * \\\n",
    "            scale[:weight.size(0), :weight.size(1)]\n",
    "\n",
    "        weight_ori = weight\n",
    "\n",
    "        ###### smooth start ######\n",
    "        compress_config = CompressConfig(\n",
    "            general_linear=LinearConfig(\n",
    "                inputs=SparseQuantizeConfig(\n",
    "                    sparsity=0,\n",
    "                    quantize=True,\n",
    "                    high_bits=8,\n",
    "                    low_bits=0,\n",
    "                    bank_size=64,\n",
    "                    group_size=64,\n",
    "                    quant_method=\"per_bank\",\n",
    "                    kv_prefill_compress=False,\n",
    "                    quant_symmetric=True,\n",
    "                    fp8=False\n",
    "                ),\n",
    "                weights=SparseQuantizeConfig(\n",
    "                    sparsity=0,\n",
    "                    quantize=True,\n",
    "                    high_bits=8,\n",
    "                    low_bits=0,\n",
    "                    bank_size=64,\n",
    "                    group_size=64,\n",
    "                    quant_method=\"per_bank\",\n",
    "                    kv_prefill_compress=False,\n",
    "                    quant_symmetric=True,\n",
    "                    fp8=False\n",
    "                ),\n",
    "                outputs=SparseQuantizeConfig(\n",
    "                    sparsity=0,\n",
    "                    quantize=False,\n",
    "                    high_bits=8,\n",
    "                    low_bits=0,\n",
    "                    bank_size=64,\n",
    "                    group_size=64,\n",
    "                    quant_method=\"per_bank\",\n",
    "                    kv_prefill_compress=False,\n",
    "                    quant_symmetric=True,\n",
    "                    fp8=False\n",
    "                ),\n",
    "                smooth=True,\n",
    "                num_grids=20\n",
    "            )\n",
    "        )\n",
    "        compressed_linear = CompressedLinear(\n",
    "            in_features=weight.size(1),\n",
    "            out_features=weight.size(0),\n",
    "            bias=False,\n",
    "            compress_cfg=compress_config.general_linear\n",
    "        )\n",
    "        compressed_linear.weight.data.copy_(weight)\n",
    "        compressopt = CompressOPT(\n",
    "            module=compressed_linear,\n",
    "            compress_cfg=compress_config.general_linear\n",
    "        )\n",
    "\n",
    "        inp = torch.randn(\n",
    "            128, weight.size(1),\n",
    "            dtype=torch.bfloat16, device=compressed_linear.weight.device\n",
    "        )\n",
    "        compressopt.add_batch(inp=inp, out=None)\n",
    "        compressopt.smooth()\n",
    "        weight = compressed_linear.weight\n",
    "        smooth_scale = compressed_linear.smooth_scale\n",
    "        # print(smooth_scale.shape, smooth_scale.dtype, smooth_scale)\n",
    "        ###### smooth end ######\n",
    "        \n",
    "        # quantize: int8 weight + bfloat16 scale\n",
    "        weight = tool.transform.preprocess(weight)\n",
    "        weight, scale = tool.sym_quant(weight)\n",
    "        weight = tool.transform.postprocess(weight).to(torch.int8)\n",
    "        scale = tool.transform.postprocess(scale).to(torch.bfloat16)\n",
    "        # tqdm.write(w_name, weight.dtype, weight.shape, scale.dtype, scale.shape)\n",
    "\n",
    "        weight_new = weight.to(torch.bfloat16) * scale.repeat_interleave(64, dim=-1)\n",
    "        weight_ori = weight_ori.view(-1)\n",
    "        weight_new = weight_new.view(-1)\n",
    "        # diff = ((weight_new - weight_ori).abs() / weight_ori.abs())\n",
    "        diff = (weight_new - weight_ori).abs()\n",
    "        diff[weight_ori == 0] = 0\n",
    "        value, index = diff.max(dim=0)\n",
    "        value_ori = weight_ori[index]\n",
    "        value_new = weight_new[index]\n",
    "        tqdm.write(f\"{w_name}: {value, value_ori, value_new}\")\n",
    "\n",
    "        # update weights\n",
    "        # set_tensor(s_name, scale)\n",
    "        # set_tensor(w_name, weight)\n",
    "\n",
    "# for fpath, w_dict in tqdm(weights.items(), desc=\"Saving weights\"):\n",
    "#     out_file = os.path.join(out_weight_dir, fpath)\n",
    "#     safetensors.torch.save_file(weights[fpath], out_file)\n",
    "    # tqdm.write(f\"Saved {len(w_list)} weights to {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data\n",
    "def disable_torch_init():\n",
    "    \"\"\"Disable initialization of Pytorch.\"\"\"\n",
    "\n",
    "    def skip(*args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    torch.nn.init.normal_ = skip\n",
    "    torch.nn.init.uniform_ = skip\n",
    "    torch.nn.init.kaiming_uniform_ = skip\n",
    "\n",
    "    DeepseekV3ForCausalLM._init_weights = skip\n",
    "\n",
    "disable_torch_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name_or_path = \"/ssd01/models/DeepSeek-V3.1-Terminus\"\n",
    "model = DeepseekV3ForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepseekV3MoE(\n",
       "  (experts): ModuleList(\n",
       "    (0-255): 256 x DeepseekV3MLP(\n",
       "      (gate_proj): FP8Linear(in_features=7168, out_features=2048, bias=False)\n",
       "      (up_proj): FP8Linear(in_features=7168, out_features=2048, bias=False)\n",
       "      (down_proj): FP8Linear(in_features=2048, out_features=7168, bias=False)\n",
       "      (act_fn): SiLUActivation()\n",
       "    )\n",
       "  )\n",
       "  (gate): DeepseekV3TopkRouter()\n",
       "  (shared_experts): DeepseekV3MLP(\n",
       "    (gate_proj): FP8Linear(in_features=7168, out_features=2048, bias=False)\n",
       "    (up_proj): FP8Linear(in_features=7168, out_features=2048, bias=False)\n",
       "    (down_proj): FP8Linear(in_features=2048, out_features=7168, bias=False)\n",
       "    (act_fn): SiLUActivation()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[3].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924bcd00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 1f1e38a8-734b-49cc-b525-314f3a3d5702)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "WARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924bcd00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 1f1e38a8-734b-49cc-b525-314f3a3d5702)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924be3e0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: df2fc62b-69b4-45bd-8732-629429f16570)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "WARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924be3e0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: df2fc62b-69b4-45bd-8732-629429f16570)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924bea10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 26efeeed-7079-4018-b5d9-a0b410940e18)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "WARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924bea10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 26efeeed-7079-4018-b5d9-a0b410940e18)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "Retrying in 4s [Retry 3/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924be950>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 47e54d2c-bb62-4f40-b28e-c563c884ac4d)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "WARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924be950>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 47e54d2c-bb62-4f40-b28e-c563c884ac4d)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "Retrying in 8s [Retry 4/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924be530>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 52f7709b-b8ce-4d5f-b568-e440a4341dad)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "WARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924be530>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 52f7709b-b8ce-4d5f-b568-e440a4341dad)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "Retrying in 8s [Retry 5/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924bc910>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 573979b5-02f3-4fab-b8c5-ec23f3f678ff)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "WARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/wikitext/resolve/main/README.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9e924bc910>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 573979b5-02f3-4fab-b8c5-ec23f3f678ff)')' thrown while requesting HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md\n",
      "Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'wikitext-2-raw-v1' at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Thu Nov 13 13:52:07 2025).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'wikitext-2-raw-v1' at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Thu Nov 13 13:52:07 2025).\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (288925 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "wiki_data = load_dataset(\n",
    "    'wikitext', 'wikitext-2-raw-v1', split='test',\n",
    "    # download_mode=\"reuse_dataset_if_exists\"\n",
    ")\n",
    "wiki_enc = tokenizer(\"\\n\\n\".join(wiki_data['text']), return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 163/163 [00:24<00:00,  6.73it/s]\n",
      "Some weights of the model checkpoint at /ssd01/models/DeepSeek-V3.1-Terminus were not used when initializing DeepseekV3ForCausalLM: ['model.layers.61.eh_proj.weight', 'model.layers.61.embed_tokens.weight', 'model.layers.61.enorm.weight', 'model.layers.61.hnorm.weight', 'model.layers.61.input_layernorm.weight', 'model.layers.61.mlp.experts.0.down_proj.weight', 'model.layers.61.mlp.experts.0.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.0.gate_proj.weight', 'model.layers.61.mlp.experts.0.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.0.up_proj.weight', 'model.layers.61.mlp.experts.0.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.1.down_proj.weight', 'model.layers.61.mlp.experts.1.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.1.gate_proj.weight', 'model.layers.61.mlp.experts.1.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.1.up_proj.weight', 'model.layers.61.mlp.experts.1.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.10.down_proj.weight', 'model.layers.61.mlp.experts.10.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.10.gate_proj.weight', 'model.layers.61.mlp.experts.10.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.10.up_proj.weight', 'model.layers.61.mlp.experts.10.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.100.down_proj.weight', 'model.layers.61.mlp.experts.100.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.100.gate_proj.weight', 'model.layers.61.mlp.experts.100.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.100.up_proj.weight', 'model.layers.61.mlp.experts.100.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.101.down_proj.weight', 'model.layers.61.mlp.experts.101.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.101.gate_proj.weight', 'model.layers.61.mlp.experts.101.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.101.up_proj.weight', 'model.layers.61.mlp.experts.101.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.102.down_proj.weight', 'model.layers.61.mlp.experts.102.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.102.gate_proj.weight', 'model.layers.61.mlp.experts.102.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.102.up_proj.weight', 'model.layers.61.mlp.experts.102.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.103.down_proj.weight', 'model.layers.61.mlp.experts.103.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.103.gate_proj.weight', 'model.layers.61.mlp.experts.103.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.103.up_proj.weight', 'model.layers.61.mlp.experts.103.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.104.down_proj.weight', 'model.layers.61.mlp.experts.104.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.104.gate_proj.weight', 'model.layers.61.mlp.experts.104.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.104.up_proj.weight', 'model.layers.61.mlp.experts.104.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.105.down_proj.weight', 'model.layers.61.mlp.experts.105.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.105.gate_proj.weight', 'model.layers.61.mlp.experts.105.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.105.up_proj.weight', 'model.layers.61.mlp.experts.105.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.106.down_proj.weight', 'model.layers.61.mlp.experts.106.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.106.gate_proj.weight', 'model.layers.61.mlp.experts.106.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.106.up_proj.weight', 'model.layers.61.mlp.experts.106.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.107.down_proj.weight', 'model.layers.61.mlp.experts.107.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.107.gate_proj.weight', 'model.layers.61.mlp.experts.107.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.107.up_proj.weight', 'model.layers.61.mlp.experts.107.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.108.down_proj.weight', 'model.layers.61.mlp.experts.108.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.108.gate_proj.weight', 'model.layers.61.mlp.experts.108.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.108.up_proj.weight', 'model.layers.61.mlp.experts.108.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.109.down_proj.weight', 'model.layers.61.mlp.experts.109.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.109.gate_proj.weight', 'model.layers.61.mlp.experts.109.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.109.up_proj.weight', 'model.layers.61.mlp.experts.109.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.11.down_proj.weight', 'model.layers.61.mlp.experts.11.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.11.gate_proj.weight', 'model.layers.61.mlp.experts.11.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.11.up_proj.weight', 'model.layers.61.mlp.experts.11.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.110.down_proj.weight', 'model.layers.61.mlp.experts.110.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.110.gate_proj.weight', 'model.layers.61.mlp.experts.110.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.110.up_proj.weight', 'model.layers.61.mlp.experts.110.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.111.down_proj.weight', 'model.layers.61.mlp.experts.111.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.111.gate_proj.weight', 'model.layers.61.mlp.experts.111.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.111.up_proj.weight', 'model.layers.61.mlp.experts.111.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.112.down_proj.weight', 'model.layers.61.mlp.experts.112.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.112.gate_proj.weight', 'model.layers.61.mlp.experts.112.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.112.up_proj.weight', 'model.layers.61.mlp.experts.112.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.113.down_proj.weight', 'model.layers.61.mlp.experts.113.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.113.gate_proj.weight', 'model.layers.61.mlp.experts.113.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.113.up_proj.weight', 'model.layers.61.mlp.experts.113.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.114.down_proj.weight', 'model.layers.61.mlp.experts.114.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.114.gate_proj.weight', 'model.layers.61.mlp.experts.114.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.114.up_proj.weight', 'model.layers.61.mlp.experts.114.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.115.down_proj.weight', 'model.layers.61.mlp.experts.115.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.115.gate_proj.weight', 'model.layers.61.mlp.experts.115.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.115.up_proj.weight', 'model.layers.61.mlp.experts.115.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.116.down_proj.weight', 'model.layers.61.mlp.experts.116.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.116.gate_proj.weight', 'model.layers.61.mlp.experts.116.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.116.up_proj.weight', 'model.layers.61.mlp.experts.116.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.117.down_proj.weight', 'model.layers.61.mlp.experts.117.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.117.gate_proj.weight', 'model.layers.61.mlp.experts.117.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.117.up_proj.weight', 'model.layers.61.mlp.experts.117.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.118.down_proj.weight', 'model.layers.61.mlp.experts.118.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.118.gate_proj.weight', 'model.layers.61.mlp.experts.118.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.118.up_proj.weight', 'model.layers.61.mlp.experts.118.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.119.down_proj.weight', 'model.layers.61.mlp.experts.119.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.119.gate_proj.weight', 'model.layers.61.mlp.experts.119.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.119.up_proj.weight', 'model.layers.61.mlp.experts.119.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.12.down_proj.weight', 'model.layers.61.mlp.experts.12.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.12.gate_proj.weight', 'model.layers.61.mlp.experts.12.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.12.up_proj.weight', 'model.layers.61.mlp.experts.12.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.120.down_proj.weight', 'model.layers.61.mlp.experts.120.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.120.gate_proj.weight', 'model.layers.61.mlp.experts.120.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.120.up_proj.weight', 'model.layers.61.mlp.experts.120.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.121.down_proj.weight', 'model.layers.61.mlp.experts.121.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.121.gate_proj.weight', 'model.layers.61.mlp.experts.121.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.121.up_proj.weight', 'model.layers.61.mlp.experts.121.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.122.down_proj.weight', 'model.layers.61.mlp.experts.122.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.122.gate_proj.weight', 'model.layers.61.mlp.experts.122.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.122.up_proj.weight', 'model.layers.61.mlp.experts.122.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.123.down_proj.weight', 'model.layers.61.mlp.experts.123.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.123.gate_proj.weight', 'model.layers.61.mlp.experts.123.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.123.up_proj.weight', 'model.layers.61.mlp.experts.123.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.124.down_proj.weight', 'model.layers.61.mlp.experts.124.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.124.gate_proj.weight', 'model.layers.61.mlp.experts.124.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.124.up_proj.weight', 'model.layers.61.mlp.experts.124.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.125.down_proj.weight', 'model.layers.61.mlp.experts.125.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.125.gate_proj.weight', 'model.layers.61.mlp.experts.125.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.125.up_proj.weight', 'model.layers.61.mlp.experts.125.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.126.down_proj.weight', 'model.layers.61.mlp.experts.126.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.126.gate_proj.weight', 'model.layers.61.mlp.experts.126.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.126.up_proj.weight', 'model.layers.61.mlp.experts.126.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.127.down_proj.weight', 'model.layers.61.mlp.experts.127.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.127.gate_proj.weight', 'model.layers.61.mlp.experts.127.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.127.up_proj.weight', 'model.layers.61.mlp.experts.127.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.128.down_proj.weight', 'model.layers.61.mlp.experts.128.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.128.gate_proj.weight', 'model.layers.61.mlp.experts.128.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.128.up_proj.weight', 'model.layers.61.mlp.experts.128.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.129.down_proj.weight', 'model.layers.61.mlp.experts.129.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.129.gate_proj.weight', 'model.layers.61.mlp.experts.129.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.129.up_proj.weight', 'model.layers.61.mlp.experts.129.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.13.down_proj.weight', 'model.layers.61.mlp.experts.13.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.13.gate_proj.weight', 'model.layers.61.mlp.experts.13.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.13.up_proj.weight', 'model.layers.61.mlp.experts.13.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.130.down_proj.weight', 'model.layers.61.mlp.experts.130.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.130.gate_proj.weight', 'model.layers.61.mlp.experts.130.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.130.up_proj.weight', 'model.layers.61.mlp.experts.130.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.131.down_proj.weight', 'model.layers.61.mlp.experts.131.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.131.gate_proj.weight', 'model.layers.61.mlp.experts.131.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.131.up_proj.weight', 'model.layers.61.mlp.experts.131.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.132.down_proj.weight', 'model.layers.61.mlp.experts.132.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.132.gate_proj.weight', 'model.layers.61.mlp.experts.132.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.132.up_proj.weight', 'model.layers.61.mlp.experts.132.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.133.down_proj.weight', 'model.layers.61.mlp.experts.133.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.133.gate_proj.weight', 'model.layers.61.mlp.experts.133.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.133.up_proj.weight', 'model.layers.61.mlp.experts.133.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.134.down_proj.weight', 'model.layers.61.mlp.experts.134.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.134.gate_proj.weight', 'model.layers.61.mlp.experts.134.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.134.up_proj.weight', 'model.layers.61.mlp.experts.134.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.135.down_proj.weight', 'model.layers.61.mlp.experts.135.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.135.gate_proj.weight', 'model.layers.61.mlp.experts.135.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.135.up_proj.weight', 'model.layers.61.mlp.experts.135.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.136.down_proj.weight', 'model.layers.61.mlp.experts.136.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.136.gate_proj.weight', 'model.layers.61.mlp.experts.136.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.136.up_proj.weight', 'model.layers.61.mlp.experts.136.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.137.down_proj.weight', 'model.layers.61.mlp.experts.137.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.137.gate_proj.weight', 'model.layers.61.mlp.experts.137.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.137.up_proj.weight', 'model.layers.61.mlp.experts.137.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.138.down_proj.weight', 'model.layers.61.mlp.experts.138.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.138.gate_proj.weight', 'model.layers.61.mlp.experts.138.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.138.up_proj.weight', 'model.layers.61.mlp.experts.138.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.139.down_proj.weight', 'model.layers.61.mlp.experts.139.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.139.gate_proj.weight', 'model.layers.61.mlp.experts.139.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.139.up_proj.weight', 'model.layers.61.mlp.experts.139.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.14.down_proj.weight', 'model.layers.61.mlp.experts.14.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.14.gate_proj.weight', 'model.layers.61.mlp.experts.14.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.14.up_proj.weight', 'model.layers.61.mlp.experts.14.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.140.down_proj.weight', 'model.layers.61.mlp.experts.140.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.140.gate_proj.weight', 'model.layers.61.mlp.experts.140.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.140.up_proj.weight', 'model.layers.61.mlp.experts.140.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.141.down_proj.weight', 'model.layers.61.mlp.experts.141.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.141.gate_proj.weight', 'model.layers.61.mlp.experts.141.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.141.up_proj.weight', 'model.layers.61.mlp.experts.141.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.142.down_proj.weight', 'model.layers.61.mlp.experts.142.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.142.gate_proj.weight', 'model.layers.61.mlp.experts.142.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.142.up_proj.weight', 'model.layers.61.mlp.experts.142.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.143.down_proj.weight', 'model.layers.61.mlp.experts.143.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.143.gate_proj.weight', 'model.layers.61.mlp.experts.143.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.143.up_proj.weight', 'model.layers.61.mlp.experts.143.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.144.down_proj.weight', 'model.layers.61.mlp.experts.144.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.144.gate_proj.weight', 'model.layers.61.mlp.experts.144.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.144.up_proj.weight', 'model.layers.61.mlp.experts.144.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.145.down_proj.weight', 'model.layers.61.mlp.experts.145.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.145.gate_proj.weight', 'model.layers.61.mlp.experts.145.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.145.up_proj.weight', 'model.layers.61.mlp.experts.145.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.146.down_proj.weight', 'model.layers.61.mlp.experts.146.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.146.gate_proj.weight', 'model.layers.61.mlp.experts.146.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.146.up_proj.weight', 'model.layers.61.mlp.experts.146.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.147.down_proj.weight', 'model.layers.61.mlp.experts.147.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.147.gate_proj.weight', 'model.layers.61.mlp.experts.147.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.147.up_proj.weight', 'model.layers.61.mlp.experts.147.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.148.down_proj.weight', 'model.layers.61.mlp.experts.148.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.148.gate_proj.weight', 'model.layers.61.mlp.experts.148.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.148.up_proj.weight', 'model.layers.61.mlp.experts.148.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.149.down_proj.weight', 'model.layers.61.mlp.experts.149.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.149.gate_proj.weight', 'model.layers.61.mlp.experts.149.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.149.up_proj.weight', 'model.layers.61.mlp.experts.149.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.15.down_proj.weight', 'model.layers.61.mlp.experts.15.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.15.gate_proj.weight', 'model.layers.61.mlp.experts.15.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.15.up_proj.weight', 'model.layers.61.mlp.experts.15.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.150.down_proj.weight', 'model.layers.61.mlp.experts.150.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.150.gate_proj.weight', 'model.layers.61.mlp.experts.150.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.150.up_proj.weight', 'model.layers.61.mlp.experts.150.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.151.down_proj.weight', 'model.layers.61.mlp.experts.151.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.151.gate_proj.weight', 'model.layers.61.mlp.experts.151.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.151.up_proj.weight', 'model.layers.61.mlp.experts.151.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.152.down_proj.weight', 'model.layers.61.mlp.experts.152.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.152.gate_proj.weight', 'model.layers.61.mlp.experts.152.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.152.up_proj.weight', 'model.layers.61.mlp.experts.152.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.153.down_proj.weight', 'model.layers.61.mlp.experts.153.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.153.gate_proj.weight', 'model.layers.61.mlp.experts.153.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.153.up_proj.weight', 'model.layers.61.mlp.experts.153.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.154.down_proj.weight', 'model.layers.61.mlp.experts.154.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.154.gate_proj.weight', 'model.layers.61.mlp.experts.154.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.154.up_proj.weight', 'model.layers.61.mlp.experts.154.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.155.down_proj.weight', 'model.layers.61.mlp.experts.155.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.155.gate_proj.weight', 'model.layers.61.mlp.experts.155.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.155.up_proj.weight', 'model.layers.61.mlp.experts.155.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.156.down_proj.weight', 'model.layers.61.mlp.experts.156.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.156.gate_proj.weight', 'model.layers.61.mlp.experts.156.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.156.up_proj.weight', 'model.layers.61.mlp.experts.156.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.157.down_proj.weight', 'model.layers.61.mlp.experts.157.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.157.gate_proj.weight', 'model.layers.61.mlp.experts.157.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.157.up_proj.weight', 'model.layers.61.mlp.experts.157.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.158.down_proj.weight', 'model.layers.61.mlp.experts.158.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.158.gate_proj.weight', 'model.layers.61.mlp.experts.158.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.158.up_proj.weight', 'model.layers.61.mlp.experts.158.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.159.down_proj.weight', 'model.layers.61.mlp.experts.159.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.159.gate_proj.weight', 'model.layers.61.mlp.experts.159.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.159.up_proj.weight', 'model.layers.61.mlp.experts.159.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.16.down_proj.weight', 'model.layers.61.mlp.experts.16.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.16.gate_proj.weight', 'model.layers.61.mlp.experts.16.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.16.up_proj.weight', 'model.layers.61.mlp.experts.16.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.160.down_proj.weight', 'model.layers.61.mlp.experts.160.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.160.gate_proj.weight', 'model.layers.61.mlp.experts.160.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.160.up_proj.weight', 'model.layers.61.mlp.experts.160.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.161.down_proj.weight', 'model.layers.61.mlp.experts.161.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.161.gate_proj.weight', 'model.layers.61.mlp.experts.161.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.161.up_proj.weight', 'model.layers.61.mlp.experts.161.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.162.down_proj.weight', 'model.layers.61.mlp.experts.162.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.162.gate_proj.weight', 'model.layers.61.mlp.experts.162.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.162.up_proj.weight', 'model.layers.61.mlp.experts.162.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.163.down_proj.weight', 'model.layers.61.mlp.experts.163.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.163.gate_proj.weight', 'model.layers.61.mlp.experts.163.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.163.up_proj.weight', 'model.layers.61.mlp.experts.163.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.164.down_proj.weight', 'model.layers.61.mlp.experts.164.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.164.gate_proj.weight', 'model.layers.61.mlp.experts.164.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.164.up_proj.weight', 'model.layers.61.mlp.experts.164.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.165.down_proj.weight', 'model.layers.61.mlp.experts.165.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.165.gate_proj.weight', 'model.layers.61.mlp.experts.165.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.165.up_proj.weight', 'model.layers.61.mlp.experts.165.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.166.down_proj.weight', 'model.layers.61.mlp.experts.166.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.166.gate_proj.weight', 'model.layers.61.mlp.experts.166.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.166.up_proj.weight', 'model.layers.61.mlp.experts.166.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.167.down_proj.weight', 'model.layers.61.mlp.experts.167.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.167.gate_proj.weight', 'model.layers.61.mlp.experts.167.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.167.up_proj.weight', 'model.layers.61.mlp.experts.167.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.168.down_proj.weight', 'model.layers.61.mlp.experts.168.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.168.gate_proj.weight', 'model.layers.61.mlp.experts.168.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.168.up_proj.weight', 'model.layers.61.mlp.experts.168.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.169.down_proj.weight', 'model.layers.61.mlp.experts.169.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.169.gate_proj.weight', 'model.layers.61.mlp.experts.169.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.169.up_proj.weight', 'model.layers.61.mlp.experts.169.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.17.down_proj.weight', 'model.layers.61.mlp.experts.17.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.17.gate_proj.weight', 'model.layers.61.mlp.experts.17.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.17.up_proj.weight', 'model.layers.61.mlp.experts.17.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.170.down_proj.weight', 'model.layers.61.mlp.experts.170.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.170.gate_proj.weight', 'model.layers.61.mlp.experts.170.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.170.up_proj.weight', 'model.layers.61.mlp.experts.170.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.171.down_proj.weight', 'model.layers.61.mlp.experts.171.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.171.gate_proj.weight', 'model.layers.61.mlp.experts.171.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.171.up_proj.weight', 'model.layers.61.mlp.experts.171.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.172.down_proj.weight', 'model.layers.61.mlp.experts.172.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.172.gate_proj.weight', 'model.layers.61.mlp.experts.172.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.172.up_proj.weight', 'model.layers.61.mlp.experts.172.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.173.down_proj.weight', 'model.layers.61.mlp.experts.173.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.173.gate_proj.weight', 'model.layers.61.mlp.experts.173.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.173.up_proj.weight', 'model.layers.61.mlp.experts.173.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.174.down_proj.weight', 'model.layers.61.mlp.experts.174.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.174.gate_proj.weight', 'model.layers.61.mlp.experts.174.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.174.up_proj.weight', 'model.layers.61.mlp.experts.174.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.175.down_proj.weight', 'model.layers.61.mlp.experts.175.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.175.gate_proj.weight', 'model.layers.61.mlp.experts.175.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.175.up_proj.weight', 'model.layers.61.mlp.experts.175.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.176.down_proj.weight', 'model.layers.61.mlp.experts.176.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.176.gate_proj.weight', 'model.layers.61.mlp.experts.176.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.176.up_proj.weight', 'model.layers.61.mlp.experts.176.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.177.down_proj.weight', 'model.layers.61.mlp.experts.177.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.177.gate_proj.weight', 'model.layers.61.mlp.experts.177.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.177.up_proj.weight', 'model.layers.61.mlp.experts.177.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.178.down_proj.weight', 'model.layers.61.mlp.experts.178.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.178.gate_proj.weight', 'model.layers.61.mlp.experts.178.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.178.up_proj.weight', 'model.layers.61.mlp.experts.178.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.179.down_proj.weight', 'model.layers.61.mlp.experts.179.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.179.gate_proj.weight', 'model.layers.61.mlp.experts.179.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.179.up_proj.weight', 'model.layers.61.mlp.experts.179.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.18.down_proj.weight', 'model.layers.61.mlp.experts.18.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.18.gate_proj.weight', 'model.layers.61.mlp.experts.18.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.18.up_proj.weight', 'model.layers.61.mlp.experts.18.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.180.down_proj.weight', 'model.layers.61.mlp.experts.180.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.180.gate_proj.weight', 'model.layers.61.mlp.experts.180.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.180.up_proj.weight', 'model.layers.61.mlp.experts.180.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.181.down_proj.weight', 'model.layers.61.mlp.experts.181.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.181.gate_proj.weight', 'model.layers.61.mlp.experts.181.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.181.up_proj.weight', 'model.layers.61.mlp.experts.181.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.182.down_proj.weight', 'model.layers.61.mlp.experts.182.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.182.gate_proj.weight', 'model.layers.61.mlp.experts.182.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.182.up_proj.weight', 'model.layers.61.mlp.experts.182.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.183.down_proj.weight', 'model.layers.61.mlp.experts.183.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.183.gate_proj.weight', 'model.layers.61.mlp.experts.183.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.183.up_proj.weight', 'model.layers.61.mlp.experts.183.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.184.down_proj.weight', 'model.layers.61.mlp.experts.184.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.184.gate_proj.weight', 'model.layers.61.mlp.experts.184.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.184.up_proj.weight', 'model.layers.61.mlp.experts.184.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.185.down_proj.weight', 'model.layers.61.mlp.experts.185.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.185.gate_proj.weight', 'model.layers.61.mlp.experts.185.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.185.up_proj.weight', 'model.layers.61.mlp.experts.185.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.186.down_proj.weight', 'model.layers.61.mlp.experts.186.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.186.gate_proj.weight', 'model.layers.61.mlp.experts.186.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.186.up_proj.weight', 'model.layers.61.mlp.experts.186.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.187.down_proj.weight', 'model.layers.61.mlp.experts.187.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.187.gate_proj.weight', 'model.layers.61.mlp.experts.187.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.187.up_proj.weight', 'model.layers.61.mlp.experts.187.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.188.down_proj.weight', 'model.layers.61.mlp.experts.188.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.188.gate_proj.weight', 'model.layers.61.mlp.experts.188.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.188.up_proj.weight', 'model.layers.61.mlp.experts.188.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.189.down_proj.weight', 'model.layers.61.mlp.experts.189.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.189.gate_proj.weight', 'model.layers.61.mlp.experts.189.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.189.up_proj.weight', 'model.layers.61.mlp.experts.189.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.19.down_proj.weight', 'model.layers.61.mlp.experts.19.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.19.gate_proj.weight', 'model.layers.61.mlp.experts.19.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.19.up_proj.weight', 'model.layers.61.mlp.experts.19.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.190.down_proj.weight', 'model.layers.61.mlp.experts.190.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.190.gate_proj.weight', 'model.layers.61.mlp.experts.190.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.190.up_proj.weight', 'model.layers.61.mlp.experts.190.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.191.down_proj.weight', 'model.layers.61.mlp.experts.191.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.191.gate_proj.weight', 'model.layers.61.mlp.experts.191.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.191.up_proj.weight', 'model.layers.61.mlp.experts.191.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.192.down_proj.weight', 'model.layers.61.mlp.experts.192.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.192.gate_proj.weight', 'model.layers.61.mlp.experts.192.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.192.up_proj.weight', 'model.layers.61.mlp.experts.192.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.193.down_proj.weight', 'model.layers.61.mlp.experts.193.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.193.gate_proj.weight', 'model.layers.61.mlp.experts.193.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.193.up_proj.weight', 'model.layers.61.mlp.experts.193.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.194.down_proj.weight', 'model.layers.61.mlp.experts.194.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.194.gate_proj.weight', 'model.layers.61.mlp.experts.194.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.194.up_proj.weight', 'model.layers.61.mlp.experts.194.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.195.down_proj.weight', 'model.layers.61.mlp.experts.195.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.195.gate_proj.weight', 'model.layers.61.mlp.experts.195.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.195.up_proj.weight', 'model.layers.61.mlp.experts.195.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.196.down_proj.weight', 'model.layers.61.mlp.experts.196.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.196.gate_proj.weight', 'model.layers.61.mlp.experts.196.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.196.up_proj.weight', 'model.layers.61.mlp.experts.196.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.197.down_proj.weight', 'model.layers.61.mlp.experts.197.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.197.gate_proj.weight', 'model.layers.61.mlp.experts.197.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.197.up_proj.weight', 'model.layers.61.mlp.experts.197.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.198.down_proj.weight', 'model.layers.61.mlp.experts.198.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.198.gate_proj.weight', 'model.layers.61.mlp.experts.198.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.198.up_proj.weight', 'model.layers.61.mlp.experts.198.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.199.down_proj.weight', 'model.layers.61.mlp.experts.199.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.199.gate_proj.weight', 'model.layers.61.mlp.experts.199.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.199.up_proj.weight', 'model.layers.61.mlp.experts.199.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.2.down_proj.weight', 'model.layers.61.mlp.experts.2.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.2.gate_proj.weight', 'model.layers.61.mlp.experts.2.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.2.up_proj.weight', 'model.layers.61.mlp.experts.2.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.20.down_proj.weight', 'model.layers.61.mlp.experts.20.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.20.gate_proj.weight', 'model.layers.61.mlp.experts.20.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.20.up_proj.weight', 'model.layers.61.mlp.experts.20.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.200.down_proj.weight', 'model.layers.61.mlp.experts.200.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.200.gate_proj.weight', 'model.layers.61.mlp.experts.200.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.200.up_proj.weight', 'model.layers.61.mlp.experts.200.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.201.down_proj.weight', 'model.layers.61.mlp.experts.201.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.201.gate_proj.weight', 'model.layers.61.mlp.experts.201.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.201.up_proj.weight', 'model.layers.61.mlp.experts.201.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.202.down_proj.weight', 'model.layers.61.mlp.experts.202.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.202.gate_proj.weight', 'model.layers.61.mlp.experts.202.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.202.up_proj.weight', 'model.layers.61.mlp.experts.202.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.203.down_proj.weight', 'model.layers.61.mlp.experts.203.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.203.gate_proj.weight', 'model.layers.61.mlp.experts.203.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.203.up_proj.weight', 'model.layers.61.mlp.experts.203.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.204.down_proj.weight', 'model.layers.61.mlp.experts.204.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.204.gate_proj.weight', 'model.layers.61.mlp.experts.204.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.204.up_proj.weight', 'model.layers.61.mlp.experts.204.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.205.down_proj.weight', 'model.layers.61.mlp.experts.205.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.205.gate_proj.weight', 'model.layers.61.mlp.experts.205.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.205.up_proj.weight', 'model.layers.61.mlp.experts.205.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.206.down_proj.weight', 'model.layers.61.mlp.experts.206.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.206.gate_proj.weight', 'model.layers.61.mlp.experts.206.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.206.up_proj.weight', 'model.layers.61.mlp.experts.206.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.207.down_proj.weight', 'model.layers.61.mlp.experts.207.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.207.gate_proj.weight', 'model.layers.61.mlp.experts.207.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.207.up_proj.weight', 'model.layers.61.mlp.experts.207.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.208.down_proj.weight', 'model.layers.61.mlp.experts.208.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.208.gate_proj.weight', 'model.layers.61.mlp.experts.208.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.208.up_proj.weight', 'model.layers.61.mlp.experts.208.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.209.down_proj.weight', 'model.layers.61.mlp.experts.209.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.209.gate_proj.weight', 'model.layers.61.mlp.experts.209.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.209.up_proj.weight', 'model.layers.61.mlp.experts.209.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.21.down_proj.weight', 'model.layers.61.mlp.experts.21.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.21.gate_proj.weight', 'model.layers.61.mlp.experts.21.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.21.up_proj.weight', 'model.layers.61.mlp.experts.21.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.210.down_proj.weight', 'model.layers.61.mlp.experts.210.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.210.gate_proj.weight', 'model.layers.61.mlp.experts.210.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.210.up_proj.weight', 'model.layers.61.mlp.experts.210.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.211.down_proj.weight', 'model.layers.61.mlp.experts.211.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.211.gate_proj.weight', 'model.layers.61.mlp.experts.211.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.211.up_proj.weight', 'model.layers.61.mlp.experts.211.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.212.down_proj.weight', 'model.layers.61.mlp.experts.212.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.212.gate_proj.weight', 'model.layers.61.mlp.experts.212.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.212.up_proj.weight', 'model.layers.61.mlp.experts.212.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.213.down_proj.weight', 'model.layers.61.mlp.experts.213.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.213.gate_proj.weight', 'model.layers.61.mlp.experts.213.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.213.up_proj.weight', 'model.layers.61.mlp.experts.213.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.214.down_proj.weight', 'model.layers.61.mlp.experts.214.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.214.gate_proj.weight', 'model.layers.61.mlp.experts.214.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.214.up_proj.weight', 'model.layers.61.mlp.experts.214.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.215.down_proj.weight', 'model.layers.61.mlp.experts.215.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.215.gate_proj.weight', 'model.layers.61.mlp.experts.215.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.215.up_proj.weight', 'model.layers.61.mlp.experts.215.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.216.down_proj.weight', 'model.layers.61.mlp.experts.216.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.216.gate_proj.weight', 'model.layers.61.mlp.experts.216.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.216.up_proj.weight', 'model.layers.61.mlp.experts.216.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.217.down_proj.weight', 'model.layers.61.mlp.experts.217.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.217.gate_proj.weight', 'model.layers.61.mlp.experts.217.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.217.up_proj.weight', 'model.layers.61.mlp.experts.217.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.218.down_proj.weight', 'model.layers.61.mlp.experts.218.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.218.gate_proj.weight', 'model.layers.61.mlp.experts.218.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.218.up_proj.weight', 'model.layers.61.mlp.experts.218.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.219.down_proj.weight', 'model.layers.61.mlp.experts.219.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.219.gate_proj.weight', 'model.layers.61.mlp.experts.219.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.219.up_proj.weight', 'model.layers.61.mlp.experts.219.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.22.down_proj.weight', 'model.layers.61.mlp.experts.22.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.22.gate_proj.weight', 'model.layers.61.mlp.experts.22.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.22.up_proj.weight', 'model.layers.61.mlp.experts.22.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.220.down_proj.weight', 'model.layers.61.mlp.experts.220.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.220.gate_proj.weight', 'model.layers.61.mlp.experts.220.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.220.up_proj.weight', 'model.layers.61.mlp.experts.220.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.221.down_proj.weight', 'model.layers.61.mlp.experts.221.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.221.gate_proj.weight', 'model.layers.61.mlp.experts.221.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.221.up_proj.weight', 'model.layers.61.mlp.experts.221.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.222.down_proj.weight', 'model.layers.61.mlp.experts.222.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.222.gate_proj.weight', 'model.layers.61.mlp.experts.222.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.222.up_proj.weight', 'model.layers.61.mlp.experts.222.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.223.down_proj.weight', 'model.layers.61.mlp.experts.223.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.223.gate_proj.weight', 'model.layers.61.mlp.experts.223.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.223.up_proj.weight', 'model.layers.61.mlp.experts.223.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.224.down_proj.weight', 'model.layers.61.mlp.experts.224.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.224.gate_proj.weight', 'model.layers.61.mlp.experts.224.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.224.up_proj.weight', 'model.layers.61.mlp.experts.224.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.225.down_proj.weight', 'model.layers.61.mlp.experts.225.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.225.gate_proj.weight', 'model.layers.61.mlp.experts.225.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.225.up_proj.weight', 'model.layers.61.mlp.experts.225.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.226.down_proj.weight', 'model.layers.61.mlp.experts.226.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.226.gate_proj.weight', 'model.layers.61.mlp.experts.226.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.226.up_proj.weight', 'model.layers.61.mlp.experts.226.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.227.down_proj.weight', 'model.layers.61.mlp.experts.227.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.227.gate_proj.weight', 'model.layers.61.mlp.experts.227.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.227.up_proj.weight', 'model.layers.61.mlp.experts.227.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.228.down_proj.weight', 'model.layers.61.mlp.experts.228.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.228.gate_proj.weight', 'model.layers.61.mlp.experts.228.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.228.up_proj.weight', 'model.layers.61.mlp.experts.228.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.229.down_proj.weight', 'model.layers.61.mlp.experts.229.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.229.gate_proj.weight', 'model.layers.61.mlp.experts.229.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.229.up_proj.weight', 'model.layers.61.mlp.experts.229.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.23.down_proj.weight', 'model.layers.61.mlp.experts.23.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.23.gate_proj.weight', 'model.layers.61.mlp.experts.23.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.23.up_proj.weight', 'model.layers.61.mlp.experts.23.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.230.down_proj.weight', 'model.layers.61.mlp.experts.230.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.230.gate_proj.weight', 'model.layers.61.mlp.experts.230.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.230.up_proj.weight', 'model.layers.61.mlp.experts.230.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.231.down_proj.weight', 'model.layers.61.mlp.experts.231.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.231.gate_proj.weight', 'model.layers.61.mlp.experts.231.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.231.up_proj.weight', 'model.layers.61.mlp.experts.231.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.232.down_proj.weight', 'model.layers.61.mlp.experts.232.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.232.gate_proj.weight', 'model.layers.61.mlp.experts.232.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.232.up_proj.weight', 'model.layers.61.mlp.experts.232.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.233.down_proj.weight', 'model.layers.61.mlp.experts.233.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.233.gate_proj.weight', 'model.layers.61.mlp.experts.233.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.233.up_proj.weight', 'model.layers.61.mlp.experts.233.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.234.down_proj.weight', 'model.layers.61.mlp.experts.234.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.234.gate_proj.weight', 'model.layers.61.mlp.experts.234.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.234.up_proj.weight', 'model.layers.61.mlp.experts.234.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.235.down_proj.weight', 'model.layers.61.mlp.experts.235.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.235.gate_proj.weight', 'model.layers.61.mlp.experts.235.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.235.up_proj.weight', 'model.layers.61.mlp.experts.235.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.236.down_proj.weight', 'model.layers.61.mlp.experts.236.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.236.gate_proj.weight', 'model.layers.61.mlp.experts.236.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.236.up_proj.weight', 'model.layers.61.mlp.experts.236.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.237.down_proj.weight', 'model.layers.61.mlp.experts.237.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.237.gate_proj.weight', 'model.layers.61.mlp.experts.237.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.237.up_proj.weight', 'model.layers.61.mlp.experts.237.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.238.down_proj.weight', 'model.layers.61.mlp.experts.238.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.238.gate_proj.weight', 'model.layers.61.mlp.experts.238.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.238.up_proj.weight', 'model.layers.61.mlp.experts.238.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.239.down_proj.weight', 'model.layers.61.mlp.experts.239.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.239.gate_proj.weight', 'model.layers.61.mlp.experts.239.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.239.up_proj.weight', 'model.layers.61.mlp.experts.239.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.24.down_proj.weight', 'model.layers.61.mlp.experts.24.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.24.gate_proj.weight', 'model.layers.61.mlp.experts.24.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.24.up_proj.weight', 'model.layers.61.mlp.experts.24.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.240.down_proj.weight', 'model.layers.61.mlp.experts.240.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.240.gate_proj.weight', 'model.layers.61.mlp.experts.240.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.240.up_proj.weight', 'model.layers.61.mlp.experts.240.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.241.down_proj.weight', 'model.layers.61.mlp.experts.241.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.241.gate_proj.weight', 'model.layers.61.mlp.experts.241.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.241.up_proj.weight', 'model.layers.61.mlp.experts.241.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.242.down_proj.weight', 'model.layers.61.mlp.experts.242.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.242.gate_proj.weight', 'model.layers.61.mlp.experts.242.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.242.up_proj.weight', 'model.layers.61.mlp.experts.242.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.243.down_proj.weight', 'model.layers.61.mlp.experts.243.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.243.gate_proj.weight', 'model.layers.61.mlp.experts.243.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.243.up_proj.weight', 'model.layers.61.mlp.experts.243.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.244.down_proj.weight', 'model.layers.61.mlp.experts.244.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.244.gate_proj.weight', 'model.layers.61.mlp.experts.244.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.244.up_proj.weight', 'model.layers.61.mlp.experts.244.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.245.down_proj.weight', 'model.layers.61.mlp.experts.245.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.245.gate_proj.weight', 'model.layers.61.mlp.experts.245.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.245.up_proj.weight', 'model.layers.61.mlp.experts.245.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.246.down_proj.weight', 'model.layers.61.mlp.experts.246.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.246.gate_proj.weight', 'model.layers.61.mlp.experts.246.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.246.up_proj.weight', 'model.layers.61.mlp.experts.246.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.247.down_proj.weight', 'model.layers.61.mlp.experts.247.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.247.gate_proj.weight', 'model.layers.61.mlp.experts.247.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.247.up_proj.weight', 'model.layers.61.mlp.experts.247.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.248.down_proj.weight', 'model.layers.61.mlp.experts.248.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.248.gate_proj.weight', 'model.layers.61.mlp.experts.248.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.248.up_proj.weight', 'model.layers.61.mlp.experts.248.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.249.down_proj.weight', 'model.layers.61.mlp.experts.249.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.249.gate_proj.weight', 'model.layers.61.mlp.experts.249.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.249.up_proj.weight', 'model.layers.61.mlp.experts.249.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.25.down_proj.weight', 'model.layers.61.mlp.experts.25.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.25.gate_proj.weight', 'model.layers.61.mlp.experts.25.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.25.up_proj.weight', 'model.layers.61.mlp.experts.25.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.250.down_proj.weight', 'model.layers.61.mlp.experts.250.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.250.gate_proj.weight', 'model.layers.61.mlp.experts.250.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.250.up_proj.weight', 'model.layers.61.mlp.experts.250.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.251.down_proj.weight', 'model.layers.61.mlp.experts.251.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.251.gate_proj.weight', 'model.layers.61.mlp.experts.251.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.251.up_proj.weight', 'model.layers.61.mlp.experts.251.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.252.down_proj.weight', 'model.layers.61.mlp.experts.252.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.252.gate_proj.weight', 'model.layers.61.mlp.experts.252.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.252.up_proj.weight', 'model.layers.61.mlp.experts.252.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.253.down_proj.weight', 'model.layers.61.mlp.experts.253.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.253.gate_proj.weight', 'model.layers.61.mlp.experts.253.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.253.up_proj.weight', 'model.layers.61.mlp.experts.253.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.254.down_proj.weight', 'model.layers.61.mlp.experts.254.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.254.gate_proj.weight', 'model.layers.61.mlp.experts.254.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.254.up_proj.weight', 'model.layers.61.mlp.experts.254.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.255.down_proj.weight', 'model.layers.61.mlp.experts.255.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.255.gate_proj.weight', 'model.layers.61.mlp.experts.255.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.255.up_proj.weight', 'model.layers.61.mlp.experts.255.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.26.down_proj.weight', 'model.layers.61.mlp.experts.26.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.26.gate_proj.weight', 'model.layers.61.mlp.experts.26.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.26.up_proj.weight', 'model.layers.61.mlp.experts.26.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.27.down_proj.weight', 'model.layers.61.mlp.experts.27.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.27.gate_proj.weight', 'model.layers.61.mlp.experts.27.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.27.up_proj.weight', 'model.layers.61.mlp.experts.27.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.28.down_proj.weight', 'model.layers.61.mlp.experts.28.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.28.gate_proj.weight', 'model.layers.61.mlp.experts.28.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.28.up_proj.weight', 'model.layers.61.mlp.experts.28.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.29.down_proj.weight', 'model.layers.61.mlp.experts.29.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.29.gate_proj.weight', 'model.layers.61.mlp.experts.29.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.29.up_proj.weight', 'model.layers.61.mlp.experts.29.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.3.down_proj.weight', 'model.layers.61.mlp.experts.3.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.3.gate_proj.weight', 'model.layers.61.mlp.experts.3.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.3.up_proj.weight', 'model.layers.61.mlp.experts.3.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.30.down_proj.weight', 'model.layers.61.mlp.experts.30.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.30.gate_proj.weight', 'model.layers.61.mlp.experts.30.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.30.up_proj.weight', 'model.layers.61.mlp.experts.30.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.31.down_proj.weight', 'model.layers.61.mlp.experts.31.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.31.gate_proj.weight', 'model.layers.61.mlp.experts.31.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.31.up_proj.weight', 'model.layers.61.mlp.experts.31.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.32.down_proj.weight', 'model.layers.61.mlp.experts.32.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.32.gate_proj.weight', 'model.layers.61.mlp.experts.32.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.32.up_proj.weight', 'model.layers.61.mlp.experts.32.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.33.down_proj.weight', 'model.layers.61.mlp.experts.33.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.33.gate_proj.weight', 'model.layers.61.mlp.experts.33.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.33.up_proj.weight', 'model.layers.61.mlp.experts.33.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.34.down_proj.weight', 'model.layers.61.mlp.experts.34.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.34.gate_proj.weight', 'model.layers.61.mlp.experts.34.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.34.up_proj.weight', 'model.layers.61.mlp.experts.34.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.35.down_proj.weight', 'model.layers.61.mlp.experts.35.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.35.gate_proj.weight', 'model.layers.61.mlp.experts.35.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.35.up_proj.weight', 'model.layers.61.mlp.experts.35.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.36.down_proj.weight', 'model.layers.61.mlp.experts.36.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.36.gate_proj.weight', 'model.layers.61.mlp.experts.36.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.36.up_proj.weight', 'model.layers.61.mlp.experts.36.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.37.down_proj.weight', 'model.layers.61.mlp.experts.37.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.37.gate_proj.weight', 'model.layers.61.mlp.experts.37.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.37.up_proj.weight', 'model.layers.61.mlp.experts.37.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.38.down_proj.weight', 'model.layers.61.mlp.experts.38.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.38.gate_proj.weight', 'model.layers.61.mlp.experts.38.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.38.up_proj.weight', 'model.layers.61.mlp.experts.38.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.39.down_proj.weight', 'model.layers.61.mlp.experts.39.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.39.gate_proj.weight', 'model.layers.61.mlp.experts.39.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.39.up_proj.weight', 'model.layers.61.mlp.experts.39.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.4.down_proj.weight', 'model.layers.61.mlp.experts.4.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.4.gate_proj.weight', 'model.layers.61.mlp.experts.4.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.4.up_proj.weight', 'model.layers.61.mlp.experts.4.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.40.down_proj.weight', 'model.layers.61.mlp.experts.40.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.40.gate_proj.weight', 'model.layers.61.mlp.experts.40.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.40.up_proj.weight', 'model.layers.61.mlp.experts.40.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.41.down_proj.weight', 'model.layers.61.mlp.experts.41.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.41.gate_proj.weight', 'model.layers.61.mlp.experts.41.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.41.up_proj.weight', 'model.layers.61.mlp.experts.41.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.42.down_proj.weight', 'model.layers.61.mlp.experts.42.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.42.gate_proj.weight', 'model.layers.61.mlp.experts.42.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.42.up_proj.weight', 'model.layers.61.mlp.experts.42.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.43.down_proj.weight', 'model.layers.61.mlp.experts.43.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.43.gate_proj.weight', 'model.layers.61.mlp.experts.43.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.43.up_proj.weight', 'model.layers.61.mlp.experts.43.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.44.down_proj.weight', 'model.layers.61.mlp.experts.44.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.44.gate_proj.weight', 'model.layers.61.mlp.experts.44.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.44.up_proj.weight', 'model.layers.61.mlp.experts.44.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.45.down_proj.weight', 'model.layers.61.mlp.experts.45.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.45.gate_proj.weight', 'model.layers.61.mlp.experts.45.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.45.up_proj.weight', 'model.layers.61.mlp.experts.45.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.46.down_proj.weight', 'model.layers.61.mlp.experts.46.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.46.gate_proj.weight', 'model.layers.61.mlp.experts.46.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.46.up_proj.weight', 'model.layers.61.mlp.experts.46.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.47.down_proj.weight', 'model.layers.61.mlp.experts.47.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.47.gate_proj.weight', 'model.layers.61.mlp.experts.47.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.47.up_proj.weight', 'model.layers.61.mlp.experts.47.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.48.down_proj.weight', 'model.layers.61.mlp.experts.48.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.48.gate_proj.weight', 'model.layers.61.mlp.experts.48.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.48.up_proj.weight', 'model.layers.61.mlp.experts.48.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.49.down_proj.weight', 'model.layers.61.mlp.experts.49.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.49.gate_proj.weight', 'model.layers.61.mlp.experts.49.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.49.up_proj.weight', 'model.layers.61.mlp.experts.49.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.5.down_proj.weight', 'model.layers.61.mlp.experts.5.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.5.gate_proj.weight', 'model.layers.61.mlp.experts.5.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.5.up_proj.weight', 'model.layers.61.mlp.experts.5.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.50.down_proj.weight', 'model.layers.61.mlp.experts.50.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.50.gate_proj.weight', 'model.layers.61.mlp.experts.50.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.50.up_proj.weight', 'model.layers.61.mlp.experts.50.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.51.down_proj.weight', 'model.layers.61.mlp.experts.51.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.51.gate_proj.weight', 'model.layers.61.mlp.experts.51.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.51.up_proj.weight', 'model.layers.61.mlp.experts.51.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.52.down_proj.weight', 'model.layers.61.mlp.experts.52.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.52.gate_proj.weight', 'model.layers.61.mlp.experts.52.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.52.up_proj.weight', 'model.layers.61.mlp.experts.52.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.53.down_proj.weight', 'model.layers.61.mlp.experts.53.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.53.gate_proj.weight', 'model.layers.61.mlp.experts.53.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.53.up_proj.weight', 'model.layers.61.mlp.experts.53.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.54.down_proj.weight', 'model.layers.61.mlp.experts.54.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.54.gate_proj.weight', 'model.layers.61.mlp.experts.54.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.54.up_proj.weight', 'model.layers.61.mlp.experts.54.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.55.down_proj.weight', 'model.layers.61.mlp.experts.55.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.55.gate_proj.weight', 'model.layers.61.mlp.experts.55.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.55.up_proj.weight', 'model.layers.61.mlp.experts.55.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.56.down_proj.weight', 'model.layers.61.mlp.experts.56.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.56.gate_proj.weight', 'model.layers.61.mlp.experts.56.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.56.up_proj.weight', 'model.layers.61.mlp.experts.56.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.57.down_proj.weight', 'model.layers.61.mlp.experts.57.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.57.gate_proj.weight', 'model.layers.61.mlp.experts.57.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.57.up_proj.weight', 'model.layers.61.mlp.experts.57.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.58.down_proj.weight', 'model.layers.61.mlp.experts.58.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.58.gate_proj.weight', 'model.layers.61.mlp.experts.58.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.58.up_proj.weight', 'model.layers.61.mlp.experts.58.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.59.down_proj.weight', 'model.layers.61.mlp.experts.59.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.59.gate_proj.weight', 'model.layers.61.mlp.experts.59.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.59.up_proj.weight', 'model.layers.61.mlp.experts.59.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.6.down_proj.weight', 'model.layers.61.mlp.experts.6.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.6.gate_proj.weight', 'model.layers.61.mlp.experts.6.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.6.up_proj.weight', 'model.layers.61.mlp.experts.6.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.60.down_proj.weight', 'model.layers.61.mlp.experts.60.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.60.gate_proj.weight', 'model.layers.61.mlp.experts.60.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.60.up_proj.weight', 'model.layers.61.mlp.experts.60.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.61.down_proj.weight', 'model.layers.61.mlp.experts.61.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.61.gate_proj.weight', 'model.layers.61.mlp.experts.61.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.61.up_proj.weight', 'model.layers.61.mlp.experts.61.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.62.down_proj.weight', 'model.layers.61.mlp.experts.62.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.62.gate_proj.weight', 'model.layers.61.mlp.experts.62.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.62.up_proj.weight', 'model.layers.61.mlp.experts.62.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.63.down_proj.weight', 'model.layers.61.mlp.experts.63.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.63.gate_proj.weight', 'model.layers.61.mlp.experts.63.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.63.up_proj.weight', 'model.layers.61.mlp.experts.63.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.64.down_proj.weight', 'model.layers.61.mlp.experts.64.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.64.gate_proj.weight', 'model.layers.61.mlp.experts.64.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.64.up_proj.weight', 'model.layers.61.mlp.experts.64.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.65.down_proj.weight', 'model.layers.61.mlp.experts.65.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.65.gate_proj.weight', 'model.layers.61.mlp.experts.65.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.65.up_proj.weight', 'model.layers.61.mlp.experts.65.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.66.down_proj.weight', 'model.layers.61.mlp.experts.66.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.66.gate_proj.weight', 'model.layers.61.mlp.experts.66.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.66.up_proj.weight', 'model.layers.61.mlp.experts.66.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.67.down_proj.weight', 'model.layers.61.mlp.experts.67.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.67.gate_proj.weight', 'model.layers.61.mlp.experts.67.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.67.up_proj.weight', 'model.layers.61.mlp.experts.67.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.68.down_proj.weight', 'model.layers.61.mlp.experts.68.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.68.gate_proj.weight', 'model.layers.61.mlp.experts.68.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.68.up_proj.weight', 'model.layers.61.mlp.experts.68.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.69.down_proj.weight', 'model.layers.61.mlp.experts.69.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.69.gate_proj.weight', 'model.layers.61.mlp.experts.69.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.69.up_proj.weight', 'model.layers.61.mlp.experts.69.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.7.down_proj.weight', 'model.layers.61.mlp.experts.7.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.7.gate_proj.weight', 'model.layers.61.mlp.experts.7.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.7.up_proj.weight', 'model.layers.61.mlp.experts.7.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.70.down_proj.weight', 'model.layers.61.mlp.experts.70.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.70.gate_proj.weight', 'model.layers.61.mlp.experts.70.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.70.up_proj.weight', 'model.layers.61.mlp.experts.70.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.71.down_proj.weight', 'model.layers.61.mlp.experts.71.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.71.gate_proj.weight', 'model.layers.61.mlp.experts.71.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.71.up_proj.weight', 'model.layers.61.mlp.experts.71.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.72.down_proj.weight', 'model.layers.61.mlp.experts.72.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.72.gate_proj.weight', 'model.layers.61.mlp.experts.72.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.72.up_proj.weight', 'model.layers.61.mlp.experts.72.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.73.down_proj.weight', 'model.layers.61.mlp.experts.73.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.73.gate_proj.weight', 'model.layers.61.mlp.experts.73.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.73.up_proj.weight', 'model.layers.61.mlp.experts.73.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.74.down_proj.weight', 'model.layers.61.mlp.experts.74.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.74.gate_proj.weight', 'model.layers.61.mlp.experts.74.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.74.up_proj.weight', 'model.layers.61.mlp.experts.74.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.75.down_proj.weight', 'model.layers.61.mlp.experts.75.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.75.gate_proj.weight', 'model.layers.61.mlp.experts.75.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.75.up_proj.weight', 'model.layers.61.mlp.experts.75.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.76.down_proj.weight', 'model.layers.61.mlp.experts.76.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.76.gate_proj.weight', 'model.layers.61.mlp.experts.76.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.76.up_proj.weight', 'model.layers.61.mlp.experts.76.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.77.down_proj.weight', 'model.layers.61.mlp.experts.77.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.77.gate_proj.weight', 'model.layers.61.mlp.experts.77.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.77.up_proj.weight', 'model.layers.61.mlp.experts.77.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.78.down_proj.weight', 'model.layers.61.mlp.experts.78.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.78.gate_proj.weight', 'model.layers.61.mlp.experts.78.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.78.up_proj.weight', 'model.layers.61.mlp.experts.78.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.79.down_proj.weight', 'model.layers.61.mlp.experts.79.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.79.gate_proj.weight', 'model.layers.61.mlp.experts.79.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.79.up_proj.weight', 'model.layers.61.mlp.experts.79.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.8.down_proj.weight', 'model.layers.61.mlp.experts.8.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.8.gate_proj.weight', 'model.layers.61.mlp.experts.8.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.8.up_proj.weight', 'model.layers.61.mlp.experts.8.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.80.down_proj.weight', 'model.layers.61.mlp.experts.80.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.80.gate_proj.weight', 'model.layers.61.mlp.experts.80.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.80.up_proj.weight', 'model.layers.61.mlp.experts.80.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.81.down_proj.weight', 'model.layers.61.mlp.experts.81.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.81.gate_proj.weight', 'model.layers.61.mlp.experts.81.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.81.up_proj.weight', 'model.layers.61.mlp.experts.81.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.82.down_proj.weight', 'model.layers.61.mlp.experts.82.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.82.gate_proj.weight', 'model.layers.61.mlp.experts.82.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.82.up_proj.weight', 'model.layers.61.mlp.experts.82.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.83.down_proj.weight', 'model.layers.61.mlp.experts.83.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.83.gate_proj.weight', 'model.layers.61.mlp.experts.83.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.83.up_proj.weight', 'model.layers.61.mlp.experts.83.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.84.down_proj.weight', 'model.layers.61.mlp.experts.84.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.84.gate_proj.weight', 'model.layers.61.mlp.experts.84.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.84.up_proj.weight', 'model.layers.61.mlp.experts.84.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.85.down_proj.weight', 'model.layers.61.mlp.experts.85.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.85.gate_proj.weight', 'model.layers.61.mlp.experts.85.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.85.up_proj.weight', 'model.layers.61.mlp.experts.85.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.86.down_proj.weight', 'model.layers.61.mlp.experts.86.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.86.gate_proj.weight', 'model.layers.61.mlp.experts.86.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.86.up_proj.weight', 'model.layers.61.mlp.experts.86.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.87.down_proj.weight', 'model.layers.61.mlp.experts.87.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.87.gate_proj.weight', 'model.layers.61.mlp.experts.87.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.87.up_proj.weight', 'model.layers.61.mlp.experts.87.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.88.down_proj.weight', 'model.layers.61.mlp.experts.88.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.88.gate_proj.weight', 'model.layers.61.mlp.experts.88.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.88.up_proj.weight', 'model.layers.61.mlp.experts.88.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.89.down_proj.weight', 'model.layers.61.mlp.experts.89.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.89.gate_proj.weight', 'model.layers.61.mlp.experts.89.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.89.up_proj.weight', 'model.layers.61.mlp.experts.89.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.9.down_proj.weight', 'model.layers.61.mlp.experts.9.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.9.gate_proj.weight', 'model.layers.61.mlp.experts.9.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.9.up_proj.weight', 'model.layers.61.mlp.experts.9.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.90.down_proj.weight', 'model.layers.61.mlp.experts.90.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.90.gate_proj.weight', 'model.layers.61.mlp.experts.90.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.90.up_proj.weight', 'model.layers.61.mlp.experts.90.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.91.down_proj.weight', 'model.layers.61.mlp.experts.91.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.91.gate_proj.weight', 'model.layers.61.mlp.experts.91.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.91.up_proj.weight', 'model.layers.61.mlp.experts.91.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.92.down_proj.weight', 'model.layers.61.mlp.experts.92.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.92.gate_proj.weight', 'model.layers.61.mlp.experts.92.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.92.up_proj.weight', 'model.layers.61.mlp.experts.92.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.93.down_proj.weight', 'model.layers.61.mlp.experts.93.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.93.gate_proj.weight', 'model.layers.61.mlp.experts.93.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.93.up_proj.weight', 'model.layers.61.mlp.experts.93.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.94.down_proj.weight', 'model.layers.61.mlp.experts.94.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.94.gate_proj.weight', 'model.layers.61.mlp.experts.94.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.94.up_proj.weight', 'model.layers.61.mlp.experts.94.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.95.down_proj.weight', 'model.layers.61.mlp.experts.95.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.95.gate_proj.weight', 'model.layers.61.mlp.experts.95.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.95.up_proj.weight', 'model.layers.61.mlp.experts.95.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.96.down_proj.weight', 'model.layers.61.mlp.experts.96.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.96.gate_proj.weight', 'model.layers.61.mlp.experts.96.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.96.up_proj.weight', 'model.layers.61.mlp.experts.96.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.97.down_proj.weight', 'model.layers.61.mlp.experts.97.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.97.gate_proj.weight', 'model.layers.61.mlp.experts.97.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.97.up_proj.weight', 'model.layers.61.mlp.experts.97.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.98.down_proj.weight', 'model.layers.61.mlp.experts.98.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.98.gate_proj.weight', 'model.layers.61.mlp.experts.98.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.98.up_proj.weight', 'model.layers.61.mlp.experts.98.up_proj.weight_scale_inv', 'model.layers.61.mlp.experts.99.down_proj.weight', 'model.layers.61.mlp.experts.99.down_proj.weight_scale_inv', 'model.layers.61.mlp.experts.99.gate_proj.weight', 'model.layers.61.mlp.experts.99.gate_proj.weight_scale_inv', 'model.layers.61.mlp.experts.99.up_proj.weight', 'model.layers.61.mlp.experts.99.up_proj.weight_scale_inv', 'model.layers.61.mlp.gate.e_score_correction_bias', 'model.layers.61.mlp.gate.weight', 'model.layers.61.mlp.shared_experts.down_proj.weight', 'model.layers.61.mlp.shared_experts.down_proj.weight_scale_inv', 'model.layers.61.mlp.shared_experts.gate_proj.weight', 'model.layers.61.mlp.shared_experts.gate_proj.weight_scale_inv', 'model.layers.61.mlp.shared_experts.up_proj.weight', 'model.layers.61.mlp.shared_experts.up_proj.weight_scale_inv', 'model.layers.61.post_attention_layernorm.weight', 'model.layers.61.self_attn.kv_a_layernorm.weight', 'model.layers.61.self_attn.kv_a_proj_with_mqa.weight', 'model.layers.61.self_attn.kv_a_proj_with_mqa.weight_scale_inv', 'model.layers.61.self_attn.kv_b_proj.weight', 'model.layers.61.self_attn.kv_b_proj.weight_scale_inv', 'model.layers.61.self_attn.o_proj.weight', 'model.layers.61.self_attn.o_proj.weight_scale_inv', 'model.layers.61.self_attn.q_a_layernorm.weight', 'model.layers.61.self_attn.q_a_proj.weight', 'model.layers.61.self_attn.q_a_proj.weight_scale_inv', 'model.layers.61.self_attn.q_b_proj.weight', 'model.layers.61.self_attn.q_b_proj.weight_scale_inv', 'model.layers.61.shared_head.head.weight', 'model.layers.61.shared_head.norm.weight']\n",
      "- This IS expected if you are initializing DeepseekV3ForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DeepseekV3ForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# online quantization\n",
    "# invalid: tensor is in meta format rather than data format\n",
    "model_name_or_path = \"/ssd01/models/DeepSeek-V3.1-Terminus\"\n",
    "cpu_model = DeepseekV3ForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 288925])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_enc[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 0.2383, 10.8750,  1.1094,  ...,  0.9688,  1.0234,  1.1406],\n",
       "         [ 8.5625,  6.4688, -0.0913,  ..., -0.1621, -0.1152, -0.0659],\n",
       "         [ 3.7344, 14.8750,  5.1250,  ...,  5.1250,  5.2500,  5.1250],\n",
       "         ...,\n",
       "         [ 0.3926, 23.1250, -1.4922,  ..., -1.6406, -1.5312, -1.2734],\n",
       "         [ 3.0469, 22.8750, -1.9297,  ..., -1.8828, -2.0312, -1.9766],\n",
       "         [ 3.0312, 21.1250, -2.2656,  ..., -2.2812, -2.1719, -2.5625]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<ToCopyBackward0>), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlen = 2048\n",
    "input_ids = wiki_enc[\"input_ids\"][:, :seqlen]\n",
    "model(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_cache = []\n",
    "kwargs_cache = []\n",
    "def save_hook(\n",
    "        module: nn.Module,\n",
    "        args: tuple[torch.Tensor, ...],\n",
    "        kwargs: dict[str, typing.Any],\n",
    "        args_cache: list,\n",
    "        kwargs_cache: list,\n",
    "        raise_err: bool=False\n",
    "    ) -> None:\n",
    "        # for i in args:\n",
    "        _list = []\n",
    "        for item in args:\n",
    "            if isinstance(item,torch.Tensor):\n",
    "                _list.append(item.to('cpu'))\n",
    "            else:\n",
    "                _list.append(copy.deepcopy(item))\n",
    "        args_cache.append(_list)\n",
    "            \n",
    "            \n",
    "        _dict = {}\n",
    "        for k,v in kwargs.items():\n",
    "            if isinstance(v,torch.Tensor):\n",
    "                _dict[k] = v.to('cpu')\n",
    "            else:\n",
    "                _dict[k] = copy.deepcopy(v)\n",
    "                \n",
    "        \n",
    "        kwargs_cache.append(_dict)\n",
    "        assert len(args_cache) == len(kwargs_cache)\n",
    "        if raise_err:\n",
    "            raise ValueError\n",
    "\n",
    "# model.model.layers[0]._forward_pre_hooks = OrderedDict()\n",
    "hook = model.model.layers[0].register_forward_pre_hook(\n",
    "    partial(\n",
    "        save_hook,\n",
    "        args_cache=args_cache,\n",
    "        kwargs_cache=kwargs_cache,\n",
    "        raise_err=True\n",
    "    ),\n",
    "    # save_hook,\n",
    "    with_kwargs=True\n",
    ")\n",
    "\n",
    "seqlen = 2048\n",
    "input_ids = wiki_enc[\"input_ids\"]\n",
    "with torch.no_grad():\n",
    "    for i in range(128):\n",
    "        try:\n",
    "                model(input_ids[:, i*seqlen: (i+1)*seqlen])\n",
    "        except ValueError:\n",
    "            pass\n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.model.layers[0]._forward_pre_hooks = OrderedDict()\n",
    "cache_dir = \"/ssd01/workspace/sglang-n/exp/data/DeepSeek-V3.1-Terminus/layer00\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "torch.save(\n",
    "    {'args': args_cache, 'kwargs': kwargs_cache},\n",
    "    os.path.join(cache_dir, 'kiwi_cache.pt')\n",
    ")\n",
    "len(args_cache), len(kwargs_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较official和mf-int8-smooth差别\n",
    "import torch\n",
    "import os\n",
    "official_dir = \"/ssd01/workspace/sglang-n/exp/data/DeepSeek-V3.1-Terminus/official-save\"\n",
    "mf_int8_dir = \"/ssd01/workspace/sglang-n/exp/data/DeepSeek-V3.1-Terminus/mf-int8-smooth-save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[1;32m     14\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-output.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m     official \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(official_dir, filename))\n\u001b[1;32m     16\u001b[0m     mf_int8 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(mf_int8_dir, filename))\n\u001b[1;32m     18\u001b[0m     max_diff, mean_diff \u001b[38;5;241m=\u001b[39m compare(official, mf_int8)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def compare(official, mf_int8):\n",
    "    diff = (official - mf_int8).abs()\n",
    "    # print(f\"Max diff: {diff.max().item():.6f}\")\n",
    "    # print(f\"Mean diff: {diff.mean().item():.6f}\")\n",
    "    # return diff\n",
    "    return diff.max().item(), diff.mean().item()\n",
    "\n",
    "mode = \"prefill\"\n",
    "# mode = \"decode\"\n",
    "max_diff_list = []\n",
    "mean_diff_list = []\n",
    "for layer in range(60):\n",
    "    filename = f\"layer{layer:02d}/{mode}-output.pt\"\n",
    "    official = torch.load(os.path.join(official_dir, filename))\n",
    "    mf_int8 = torch.load(os.path.join(mf_int8_dir, filename))\n",
    "\n",
    "    max_diff, mean_diff = compare(official, mf_int8)\n",
    "    max_diff_list.append(max_diff)\n",
    "    mean_diff_list.append(mean_diff)\n",
    "\n",
    "figure = plt.figure(figsize=(10, 3))\n",
    "ax = figure.add_subplot(1, 2, 1)\n",
    "ax.plot(max_diff_list, label=\"max_diff\")\n",
    "plt.legend()\n",
    "ax = figure.add_subplot(1, 2, 2)\n",
    "ax.plot(mean_diff_list, label=\"mean_diff\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd01/miniconda3/envs/sglang-v0.5.5.post3/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/ssd01/miniconda3/envs/sglang-v0.5.5.post3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0065), tensor(0.0012))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 比较权重\n",
    "import torch\n",
    "import safetensors\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_tensor(model_dir, name):\n",
    "    with open(os.path.join(model_dir, \"model.safetensors.index.json\")) as fid:\n",
    "        weight_map = json.load(fid)[\"weight_map\"]\n",
    "        filename = weight_map[name]\n",
    "    with safetensors.safe_open(os.path.join(model_dir, filename), framework=\"pt\") as m:\n",
    "        return m.get_tensor(name)\n",
    "\n",
    "layer_name = \"model.layers.0.self_attn.q_a_proj\"\n",
    "layer_name = \"model.layers.0.mlp.up_proj\"\n",
    "layer_name = \"model.layers.0.mlp.gate_proj\"\n",
    "layer_name = \"model.layers.3.mlp.experts.255.gate_proj\"\n",
    "layer_name = \"model.layers.3.mlp.experts.255.up_proj\"\n",
    "# layer_name = \"model.layers.3.mlp.shared_experts.gate_proj\"\n",
    "layer_name = \"model.layers.3.mlp.shared_experts.up_proj\"\n",
    "\n",
    "model_dir = \"/ssd01/models/DeepSeek-V3.1-Terminus/\"\n",
    "name = f\"{layer_name}.weight\"\n",
    "fp8_weight = get_tensor(model_dir, name)\n",
    "name = f\"{layer_name}.weight_scale_inv\"\n",
    "fp8_scale = get_tensor(model_dir, name)\n",
    "ori_weight = fp8_weight.to(fp8_scale.dtype) * fp8_scale.repeat_interleave(128, 1).repeat_interleave(128, 0)[:fp8_weight.size(0), :fp8_weight.size(1)]\n",
    "\n",
    "# model_dir = \"/ssd01/models/DeepSeek-V3.1-Terminus-MF-Int8-smooth/\"\n",
    "model_dir = \"/ssd01/models/DeepSeek-V3.1-Terminus-MF-Int8/\"\n",
    "\n",
    "model_dir = \"/ssd01/workspace/sglang-n/exp/data/DeepSeek-V3.1-Terminus-model/\"\n",
    "# model_dir = \"/ssd01/models/DeepSeek-V3.1-Terminus-MF-W8xH8L3/\"\n",
    "name = f\"{layer_name}.smooth_scale\"\n",
    "try:\n",
    "    smooth_scale = get_tensor(model_dir, name)\n",
    "except:\n",
    "    smooth_scale = 1\n",
    "\n",
    "from sglang.srt.mf_tool import generate_mask\n",
    "name = f\"{layer_name}.mask\"\n",
    "try:\n",
    "    mask = get_tensor(model_dir, name)\n",
    "except:\n",
    "    try:\n",
    "        name = f\"{layer_name}.mask_id\"\n",
    "        mask_id = get_tensor(model_dir, name)\n",
    "        mask = generate_mask(mask_id, [1, 64], dtype=torch.int8)\n",
    "    except:\n",
    "        mask = 1\n",
    "\n",
    "name = f\"{layer_name}.weight\"\n",
    "int8_weight = get_tensor(model_dir, name)\n",
    "name = f\"{layer_name}.weight_scale_inv\"\n",
    "int8_scale = get_tensor(model_dir, name)\n",
    "\n",
    "name = f\"{layer_name}.lweight_scale_inv\"\n",
    "try:\n",
    "    lint8_scale = get_tensor(model_dir, name)\n",
    "except:\n",
    "    lint8_scale = torch.ones_like(int8_scale)\n",
    "\n",
    "new_weight = (\n",
    "    int8_weight.to(int8_scale.dtype) * int8_scale.repeat_interleave(64, 1) * mask + \\\n",
    "    int8_weight.to(int8_scale.dtype) * lint8_scale.repeat_interleave(64, 1) * (1 - mask)\n",
    ") / smooth_scale\n",
    "(new_weight - ori_weight).abs().max(), (new_weight - ori_weight).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0143,  0.0072, -0.0072,  ...,  0.0104, -0.0430,  0.0000],\n",
       "         [ 0.0052,  0.0156, -0.0104,  ..., -0.0117, -0.0232,  0.0000],\n",
       "         [-0.0117, -0.0059,  0.0000,  ...,  0.0000,  0.0137, -0.0045],\n",
       "         ...,\n",
       "         [ 0.0098, -0.0049,  0.0176,  ...,  0.0000, -0.0065, -0.0130],\n",
       "         [-0.0078,  0.0039, -0.0039,  ...,  0.0000,  0.0127,  0.0085],\n",
       "         [-0.0130,  0.0130, -0.0065,  ...,  0.0000,  0.0072,  0.0072]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[ 0.0107,  0.0044, -0.0049,  ...,  0.0127, -0.0430, -0.0022],\n",
       "         [ 0.0044,  0.0146, -0.0107,  ..., -0.0098, -0.0234, -0.0011],\n",
       "         [-0.0098, -0.0078,  0.0016,  ..., -0.0011,  0.0137, -0.0037],\n",
       "         ...,\n",
       "         [ 0.0107, -0.0059,  0.0176,  ..., -0.0027, -0.0039, -0.0117],\n",
       "         [-0.0063,  0.0044, -0.0049,  ..., -0.0012,  0.0107,  0.0073],\n",
       "         [-0.0098,  0.0107, -0.0088,  ..., -0.0012,  0.0049,  0.0037]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(new_weight.size(0) // 16)\n",
    "# mask_id[:int(size / 64)], lint8_scale[:size]\n",
    "new_weight[:size, :], ori_weight[:size, :], mask[:size, :], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8, 20, 33,  ..., 47, 50, 51],\n",
       "         [ 1, 14, 18,  ..., 37, 54, 57],\n",
       "         [ 7, 26, 31,  ..., 47, 56, 60],\n",
       "         ...,\n",
       "         [ 6,  7,  8,  ..., 26, 38, 44],\n",
       "         [ 0,  3, 12,  ..., 36, 53, 54],\n",
       "         [ 2, 11, 19,  ..., 35, 60, 62]],\n",
       "\n",
       "        [[18, 19, 24,  ..., 50, 56, 57],\n",
       "         [16, 17, 18,  ..., 40, 47, 56],\n",
       "         [ 3, 15, 24,  ..., 29, 55, 57],\n",
       "         ...,\n",
       "         [ 1,  4, 18,  ..., 50, 55, 58],\n",
       "         [ 1, 13, 17,  ..., 24, 56, 57],\n",
       "         [ 2,  7, 14,  ..., 54, 59, 62]],\n",
       "\n",
       "        [[13, 17, 22,  ..., 52, 54, 56],\n",
       "         [ 0,  9, 15,  ..., 36, 39, 44],\n",
       "         [ 4, 16, 17,  ..., 33, 47, 50],\n",
       "         ...,\n",
       "         [12, 13, 16,  ..., 43, 55, 59],\n",
       "         [ 0,  8, 16,  ..., 49, 51, 59],\n",
       "         [ 4,  9, 16,  ..., 52, 59, 60]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2,  7, 10,  ..., 33, 41, 56],\n",
       "         [ 4, 19, 24,  ..., 46, 47, 58],\n",
       "         [ 4, 14, 22,  ..., 34, 42, 47],\n",
       "         ...,\n",
       "         [ 0,  7,  8,  ..., 12, 26, 58],\n",
       "         [ 4, 14, 18,  ..., 37, 54, 57],\n",
       "         [12, 21, 32,  ..., 57, 59, 62]],\n",
       "\n",
       "        [[ 1, 17, 18,  ..., 47, 57, 60],\n",
       "         [15, 26, 29,  ..., 36, 50, 59],\n",
       "         [11, 14, 19,  ..., 53, 59, 61],\n",
       "         ...,\n",
       "         [ 2,  7, 10,  ..., 49, 58, 60],\n",
       "         [11, 13, 15,  ..., 45, 48, 53],\n",
       "         [ 6,  7, 19,  ..., 55, 57, 58]],\n",
       "\n",
       "        [[ 3,  6, 15,  ..., 39, 41, 43],\n",
       "         [ 3, 11, 24,  ..., 43, 53, 63],\n",
       "         [ 8, 10, 12,  ..., 40, 46, 50],\n",
       "         ...,\n",
       "         [ 4,  9, 16,  ..., 43, 59, 61],\n",
       "         [ 4,  6,  8,  ..., 20, 35, 54],\n",
       "         [ 8, 16, 18,  ..., 42, 43, 49]]], dtype=torch.int8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang-v0.5.5.post3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
